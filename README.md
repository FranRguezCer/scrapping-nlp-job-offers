# ğŸ“Š Data Jobs in Spain â€“ End-to-End Analysis with Web Scraping & NLP

This project is an **end-to-end pipeline** that scrapes and analyzes job offers for data-related roles in Spain using **real listings from [Tecnoempleo](https://www.tecnoempleo.com/)**.

It combines:
- âœ… Web scraping with Python to collect job market data
- âœ… Exploratory Data Analysis (EDA) to identify trends
- âœ… Rule-based NLP with `spaCy` to extract structured information (tech skills, soft skills, work mode)
- âœ… A dual comparison of keyword matching vs NLP pattern matching

> Ideal for aspiring **Data Analysts** and **Junior Data Scientists** aiming to understand real job market expectations in 2025.

---

## ğŸš€ Project Highlights

- ğŸ” Scrapes 150 real job offers related to *data roles* (e.g. Data Analyst, Data Scientist, Data Engineer)
- ğŸŒ Handles listings in both **Spanish and English**
- ğŸ§  Applies multilingual NLP (`spaCy`) to detect soft/technical skills and work modality
- ğŸ“Š Compares results from basic keyword matching and smart rule-based NLP
- ğŸ§¼ Cleans, structures and enriches raw text data into actionable insights

---

## ğŸ“¦ Project Structure

```bash
data-jobs-analysis/
â”‚
â”œâ”€â”€ data/                            # All raw and processed datasets
â”‚   â”œâ”€â”€ job_offers_list.csv          # Listings scraped from Tecnoempleo (title, company, URL)
â”‚   â””â”€â”€ job_offers_detailed.csv      # Enriched offers with descriptions, metadata, tech tags
â”‚
â”œâ”€â”€ scraper/                         # Web scraping scripts
â”‚   â”œâ”€â”€ scrape_listings.py           # Scrapes multiple pages of job listings
â”‚   â””â”€â”€ scrape_offer_details.py      # Extracts detailed info from each job URL
â”‚
â”œâ”€â”€ notebooks/                       # Analysis and visualization notebooks
â”‚   â””â”€â”€ EDA_jobs.ipynb               # Exploratory data analysis and feature engineering
â”‚
â”œâ”€â”€ requirements.txt                 # List of Python dependencies
â”œâ”€â”€ README.md                        # Project documentation and summary
â””â”€â”€ .gitignore                       # Files and folders to ignore in version control
```

---

## ğŸ§° Technologies Used

- **Python** â€“ main programming language
  - `requests`, `BeautifulSoup` â€“ for HTML parsing and web scraping
  - `pandas`, `re`, `collections` â€“ for structured data manipulation and keyword extraction
  - `matplotlib`, `seaborn` â€“ for data visualization and comparisons
  - `spaCy` â€“ for NLP-based skill extraction in both **English** and **Spanish**
    - Language models used: `en_core_web_md` and `es_core_news_md`
    - `PhraseMatcher` for multilingual rule-based entity detection
  - `Jupyter Notebook` / `Google Colab` â€“ for interactive and cloud-based analysis

---

## ğŸ”§ Setup Instructions

### 1. Clone the repository
```bash
git clone https://github.com/FranRguezCer/scrapping-nlp-job-offers.git
cd scrapping-nlp-job-offers
```

### 2. (Optional but recommended) Create and activate a virtual environment
```bash
python -m venv venv-nlp
source venv-nlp/bin/activate         # Windows: .\venv-nlp\Scripts\activate
```

### 3. Install Python dependencies
```bash
pip install -r requirements.txt
```

### 4. Download spaCy language models
```bash
python -m spacy download en_core_web_md
python -m spacy download es_core_news_md
```

---

## ğŸ“Š Dataset Summary

- âœ… Offers collected with the keyword: `"data"`
- âœ… Scraped from 5+ pages of search results (a total of 150 job offers from [Tecnoempleo](tecnoempleo.com))
- âœ… Full details extracted per offer: title, company, location, description, publication date, contract type, etc.
- âœ… Technologies auto-detected from free-text job descriptions (Python, SQL, Power BI, etc.)

---

## ğŸ•¸ï¸ Web Scraping Process

The job offers were scraped from [Tecnoempleo](https://www.tecnoempleo.com/), a major Spanish tech job board.  
The scraping pipeline consists of two steps:

1. **Listing Scraper (`scrape_listings.py`)**  
   - Crawls multiple pages and collects basic info (job title, company, and URL to each job offer).

2. **Details Scraper (`scrape_offer_details.py`)**  
   - Visits each job URL to extract full descriptions, contract type, work modality, required skills, and more.

Both scripts use `requests` + `BeautifulSoup`, and results are saved into `job_offers_list.csv` and `job_offers_detailed.csv`.

---

## ğŸ““ Try the EDA and NLP analysis in Google Colab

The main notebook includes all preprocessing, skill detection, and comparisons between keyword-based and NLP-based extractions.

> âš¡ No installation needed â€” run it directly in the cloud:

<div align="center">
  <a href="https://colab.research.google.com/github/FranRguezCer/scrapping-nlp-job-offers/blob/main/notebooks/EDA_jobs.ipynb" target="_blank">
    <img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open in Colab" style="height: 40px;">
  </a>
</div>


---

## ğŸ§  Future Work

- Applying Named Entity Recognition (NER) or transformer-based models to enrich the analysis.
- Extracting salary ranges or required years of experience using NLP.
- Automating updates to track how trends evolve over time.

---

## ğŸ‘¨â€ğŸ’» Author

> Created by **[Francisco JosÃ© RodrÃ­guez Cerezo]**, aspiring data analyst with a passion for real-world applications and strong technical curiosity.  
> Currently enhancing my portfolio with practical end-to-end projects.

[LinkedIn](https://linkedin.com/in/franciscojoserodriguezcerezo) | [Portfolio](https://franrguezcer.github.io/portfolio/) | [Email](mailto:fjrguezcerezo@gmail.com)

---

## ğŸ“ License

This project is licensed under the [MIT License](LICENSE).

You are free to use, modify, and distribute this code for personal or commercial purposes, provided that proper credit is given.  
This software is provided **"as is"**, without warranty of any kind.

Â© 2025 Francisco JosÃ© RodrÃ­guez Cerezo

